{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/02 22:55:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   null|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   null|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   null|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   null|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   null|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   null|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data_path = 'data/fhv_tripdata_2019-10.csv.gz'\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(data_path)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = 'data/pq/'\n",
    "df \\\n",
    "    .repartition(6) \\\n",
    "    .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropOff_datetime', TimestampType(), True), StructField('PUlocationID', IntegerType(), True), StructField('DOlocationID', IntegerType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True), StructField('pickup_timestamp', LongType(), True), StructField('dropoff_timestamp', LongType(), True), StructField('time_difference_seconds', LongType(), True)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PUlocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOlocationID', types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.StringType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\n",
    "    (f.col('pickup_datetime') >= '2019-10-15 00:00:00')\n",
    "    & (f.col('pickup_datetime') <= '2019-10-15 23:59:59')\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp, from_unixtime, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"pickup_timestamp\", unix_timestamp(col(\"pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"dropoff_timestamp\", unix_timestamp(col(\"dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "       .withColumn(\"time_difference_seconds\", col(\"dropoff_timestamp\") - col(\"pickup_timestamp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+-----------------+-----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|pickup_timestamp|dropoff_timestamp|time_difference_seconds|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+-----------------+-----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   null|                B00009|      1569889380|       1569890100|                    720|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   null|                B00013|      1569888689|       1569888802|                    113|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   null|                B00014|      1569888703|       1569890240|                   1537|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   null|                B00014|      1569891389|       1569891467|                     78|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   null|                B00014|      1569889389|       1569889707|                    318|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   null|       B00021         |      1569888048|       1569888432|                    384|\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   null|       B00021         |      1569890843|       1569891205|                    362|\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   null|       B00021         |      1569888606|       1569889190|                    584|\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   null|       B00021         |      1569891097|       1569891974|                    877|\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   null|       B00021         |      1569889703|       1569890073|                    370|\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   null|       B00021         |      1569889877|       1569891112|                   1235|\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   null|                B00037|      1569888461|       1569888923|                    462|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   null|                B00037|      1569888818|       1569889551|                    733|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   null|                B00037|      1569890560|       1569891227|                    667|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   null|                B00037|      1569891526|       1569892211|                    685|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   null|                B00037|      1569888589|       1569888877|                    288|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   null|                B00037|      1569889355|       1569890213|                    858|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   null|                B00037|      1569891267|       1569891817|                    550|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   null|                B00037|      1569888492|       1569889727|                   1235|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   null|                  #N/A|      1569888324|       1569891183|                   2859|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+-----------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|max(time_difference_seconds)|\n",
      "+----------------------------+\n",
      "|                  2272149000|\n",
      "+----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(max(df.time_difference_seconds)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631152.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2272149000/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('data/taxi_zone_lookup.csv')\n",
    "\n",
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.join(df_zones, df.PUlocationID == df_zones.LocationID,  \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+-----------------+-----------------------+----------+-------+----+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|pickup_timestamp|dropoff_timestamp|time_difference_seconds|LocationID|Borough|Zone|service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+-----------------+-----------------------+----------+-------+----+------------+\n",
      "|              B02416|2019-10-01 00:56:00|2019-10-01 01:05:00|        null|        null|   null|                B02416|      1569891360|       1569891900|                    540|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:01:00|2019-10-01 01:17:12|        null|        null|   null|                B02416|      1569891660|       1569892632|                    972|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:34:00|2019-10-01 01:40:00|        null|        null|   null|                B02416|      1569893640|       1569894000|                    360|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:02:00|2019-10-01 01:14:36|        null|        null|   null|                B02416|      1569891720|       1569892476|                    756|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:31:00|2019-10-01 01:37:00|        null|        null|   null|                B02416|      1569893460|       1569893820|                    360|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:01:00|2019-10-01 01:17:12|        null|        null|   null|                B02416|      1569891660|       1569892632|                    972|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:12:00|2019-10-01 01:24:36|        null|        null|   null|                B02416|      1569892320|       1569893076|                    756|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:15:00|2019-10-01 01:21:00|        null|        null|   null|                B02416|      1569892500|       1569892860|                    360|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 01:24:00|2019-10-01 01:34:12|        null|        null|   null|                B02416|      1569893040|       1569893652|                    612|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 02:58:00|2019-10-01 03:04:00|        null|        null|   null|                B02416|      1569898680|       1569899040|                    360|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 02:44:00|2019-10-01 02:54:12|        null|        null|   null|                B02416|      1569897840|       1569898452|                    612|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 03:16:00|2019-10-01 03:25:00|        null|        null|   null|                B02416|      1569899760|       1569900300|                    540|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 03:47:00|2019-10-01 04:03:12|        null|        null|   null|                B02416|      1569901620|       1569902592|                    972|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 03:23:00|2019-10-01 03:35:36|        null|        null|   null|                B02416|      1569900180|       1569900936|                    756|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 04:33:00|2019-10-01 04:43:12|        null|        null|   null|                B02416|      1569904380|       1569904992|                    612|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 04:59:00|2019-10-01 05:15:12|        null|        null|   null|                B02416|      1569905940|       1569906912|                    972|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 04:38:00|2019-10-01 04:50:36|        null|        null|   null|                B02416|      1569904680|       1569905436|                    756|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 04:41:00|2019-10-01 04:53:36|        null|        null|   null|                B02416|      1569904860|       1569905616|                    756|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 04:30:00|2019-10-01 04:40:12|        null|        null|   null|                B02416|      1569904200|       1569904812|                    612|      null|   null|null|        null|\n",
      "|              B02416|2019-10-01 04:29:00|2019-10-01 04:41:36|        null|        null|   null|                B02416|      1569904140|       1569904896|                    756|      null|   null|null|        null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+-----------------+-----------------------+----------+-------+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hossam/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_join.registerTempTable('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                zone|count(zone)|\n",
      "+--------------------+-----------+\n",
      "|         Jamaica Bay|          1|\n",
      "|Governor's Island...|          2|\n",
      "| Green-Wood Cemetery|          5|\n",
      "|       Broad Channel|          8|\n",
      "|     Highbridge Park|         14|\n",
      "|        Battery Park|         15|\n",
      "|Saint Michaels Ce...|         23|\n",
      "|Breezy Point/Fort...|         25|\n",
      "|Marine Park/Floyd...|         26|\n",
      "|        Astoria Park|         29|\n",
      "|    Inwood Hill Park|         39|\n",
      "|       Willets Point|         47|\n",
      "|Forest Park/Highl...|         53|\n",
      "|  Brooklyn Navy Yard|         57|\n",
      "|        Crotona Park|         62|\n",
      "|        Country Club|         77|\n",
      "|     Freshkills Park|         89|\n",
      "|       Prospect Park|         98|\n",
      "|     Columbia Street|        105|\n",
      "|  South Williamsburg|        110|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    zone, count(zone)\n",
    "FROM\n",
    "    df\n",
    "    where PUlocationID is not null\n",
    "GROUP BY\n",
    "    1\n",
    "    order by 2 asc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
